#!/usr/bin/env python3
"""
å°çº¢ä¹¦åšä¸»ç¬”è®°è‡ªåŠ¨ä¸‹è½½å™¨

åŠŸèƒ½ï¼š
- è‡ªåŠ¨è·å–åšä¸»æ‰€æœ‰ç¬”è®°ï¼ˆå›¾ç‰‡ã€è§†é¢‘ï¼‰
- æŒ‰åšä¸»åç§°åˆ›å»ºæ–‡ä»¶å¤¹
- ä¿å­˜å®Œæ•´çš„ç¬”è®°å…ƒæ•°æ®
- æ”¯æŒCookieè®¤è¯

ä½¿ç”¨æ–¹æ³•ï¼š
    python xiaohongshu_downloader.py <åšä¸»ä¸»é¡µURL>

é…ç½®æ–‡ä»¶ï¼š
    - config.json: åŒ…å« Cookie å’Œä¸‹è½½é…ç½®
"""
import os
import sys
import json
import time
import argparse
import requests
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple

# æ·»åŠ  SDK è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'media_parser_sdk'))

from media_parser_sdk.platforms.xiaohongshu_enhanced import XiaohongshuEnhancedParser


class XiaohongshuDownloader:
    """å°çº¢ä¹¦åšä¸»ç¬”è®°ä¸‹è½½å™¨"""

    def __init__(self, cookie: str = None, output_dir: str = "downloads", delay: float = 0.5):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨

        Args:
            cookie: å°çº¢ä¹¦ Cookie
            output_dir: ä¸‹è½½ç›®å½•
            delay: è¯·æ±‚å»¶è¿Ÿï¼ˆç§’ï¼‰
        """
        self.cookie = cookie
        self.output_dir = Path(output_dir)
        self.delay = delay

        # åˆå§‹åŒ–è§£æå™¨
        self.parser = XiaohongshuEnhancedParser(cookie=cookie) if cookie else XiaohongshuEnhancedParser()

        # ä¸‹è½½ç»Ÿè®¡
        self.stats = {
            "start_time": datetime.now().isoformat(),
            "total_notes": 0,
            "successful": 0,
            "failed": 0,
            "total_images": 0,
            "total_videos": 0,
            "total_covers": 0,
            "notes": []
        }

        # HTTP è¯·æ±‚å¤´
        self.download_headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
            "Referer": "https://www.xiaohongshu.com/"
        }

    def sanitize_filename(self, name: str) -> str:
        """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
        invalid_chars = '<>:"/\\|?*'
        for char in invalid_chars:
            name = name.replace(char, '_')
        return name.strip()

    def download_file(self, url: str, filepath: str) -> Tuple[bool, Optional[str]]:
        """
        ä¸‹è½½æ–‡ä»¶

        Args:
            url: ä¸‹è½½é“¾æ¥
            filepath: ä¿å­˜è·¯å¾„

        Returns:
            (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
        """
        try:
            response = requests.get(url, headers=self.download_headers, timeout=30)
            response.raise_for_status()

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(filepath), exist_ok=True)

            with open(filepath, 'wb') as f:
                f.write(response.content)

            return True, None
        except Exception as e:
            return False, str(e)

    def download_author_notes(self, author_url: str, max_notes: Optional[int] = None) -> Dict:
        """
        ä¸‹è½½åšä¸»æ‰€æœ‰ç¬”è®°

        Args:
            author_url: åšä¸»ä¸»é¡µURL
            max_notes: æœ€å¤§ä¸‹è½½ç¬”è®°æ•°ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨

        Returns:
            ä¸‹è½½ç»“æœç»Ÿè®¡
        """
        print("="*60)
        print("å°çº¢ä¹¦åšä¸»ç¬”è®°ä¸‹è½½å™¨")
        print("="*60)
        print(f"åšä¸»é“¾æ¥: {author_url}")
        print(f"Cookie: {'âœ“ å·²æä¾›' if self.cookie else 'âœ— æœªæä¾›'}")
        print(f"æœ€å¤§ç¬”è®°æ•°: {max_notes if max_notes else 'å…¨éƒ¨'}")
        print(f"ä¸‹è½½ç›®å½•: {self.output_dir}")
        print("="*60)

        # è·å–åšä¸»ä¿¡æ¯å’Œç¬”è®°åˆ—è¡¨
        print("\n[1/3] è·å–åšä¸»ä¿¡æ¯...")
        result = self.parser.parse_author_notes_sync(
            author_url,
            max_notes=max_notes,
            fetch_detail=True
        )

        if not result.success:
            print(f"âŒ è·å–å¤±è´¥: {result.error_message}")
            return self.stats

        data = result.data
        author = data.get('author_profile', {})
        notes = data.get('notes', [])

        author_name = author.get('nickname', 'æœªçŸ¥ä½œè€…')
        author_id = author.get('user_id', 'unknown')

        print(f"âœ“ åšä¸»: {author_name}")
        print(f"âœ“ ç¬”è®°æ€»æ•°: {len(notes)}")

        # åˆ›å»ºåšä¸»æ–‡ä»¶å¤¹
        author_dir = self.output_dir / self.sanitize_filename(author_name)
        author_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜å®Œæ•´çš„ç¬”è®°æ•°æ®
        notes_json_path = author_dir / "notes_data.json"
        with open(notes_json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ“ å·²ä¿å­˜: {notes_json_path.name}")

        # ä¸‹è½½åª’ä½“æ–‡ä»¶
        print(f"\n[2/3] ä¸‹è½½åª’ä½“æ–‡ä»¶...")
        self.stats["total_notes"] = len(notes)

        for idx, note in enumerate(notes, 1):
            note_id = note.get('note_id', f'unknown_{idx}')
            title = note.get('title', f'ç¬”è®°_{idx}')

            print(f"\n[{idx}/{len(notes)}] {title}")
            print(f"  note_id: {note_id}")

            # åˆ›å»ºç¬”è®°æ–‡ä»¶å¤¹
            note_folder_name = f"{idx:02d}_{self.sanitize_filename(title[:30])}"
            note_dir = author_dir / note_folder_name
            note_dir.mkdir(exist_ok=True)

            # ä¿å­˜ç¬”è®°å…ƒæ•°æ®
            metadata_path = note_dir / "metadata.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(note, f, ensure_ascii=False, indent=2)

            note_stats = {
                "note_id": note_id,
                "title": title,
                "folder": str(note_dir),
                "images": [],
                "videos": [],
                "cover": None
            }

            # ä¸‹è½½å°é¢
            cover_image = note.get('cover_image', {})
            if cover_image and cover_image.get('url'):
                cover_url = cover_image['url']
                # è½¬æ¢ä¸º HTTPS
                if cover_url.startswith('http://'):
                    cover_url = cover_url.replace('http://', 'https://', 1)

                cover_path = note_dir / "cover.jpg"
                success, error = self.download_file(cover_url, str(cover_path))
                if success:
                    print(f"  âœ“ å°é¢å·²ä¿å­˜")
                    note_stats["cover"] = str(cover_path)
                    self.stats["total_covers"] += 1
                else:
                    print(f"  âœ— å°é¢ä¸‹è½½å¤±è´¥: {error}")

            # ä¸‹è½½å›¾ç‰‡
            images = note.get('images', [])
            if images:
                print(f"  å›¾ç‰‡: {len(images)} å¼ ")
                for img_idx, img in enumerate(images, 1):
                    img_url = img.get('url')
                    if not img_url:
                        continue

                    # è·å–æ–‡ä»¶æ‰©å±•å
                    ext = '.jpg'
                    if '.png' in img_url:
                        ext = '.png'
                    elif '.webp' in img_url:
                        ext = '.webp'

                    img_path = note_dir / f"image_{img_idx}{ext}"
                    success, error = self.download_file(img_url, str(img_path))
                    if success:
                        note_stats["images"].append(str(img_path))
                        self.stats["total_images"] += 1

                    # è¿›åº¦æ˜¾ç¤º
                    if len(images) <= 5:
                        print(f"    [{img_idx}/{len(images)}] âœ“" if success else f"    [{img_idx}/{len(images)}] âœ—")
                    elif img_idx % 5 == 0 or img_idx == len(images):
                        print(f"    [{img_idx}/{len(images)}] âœ“" if success else f"    [{img_idx}/{len(images)}] âœ—")
            else:
                print(f"  å›¾ç‰‡: 0 å¼ ")

            # ä¸‹è½½è§†é¢‘
            videos = note.get('videos', [])
            if videos:
                print(f"  è§†é¢‘: {len(videos)} ä¸ª")
                for vid_idx, vid in enumerate(videos, 1):
                    vid_url = vid.get('url')
                    if not vid_url:
                        continue

                    vid_path = note_dir / f"video_{vid_idx}.mp4"
                    success, error = self.download_file(vid_url, str(vid_path))
                    if success:
                        note_stats["videos"].append(str(vid_path))
                        self.stats["total_videos"] += 1
                        print(f"    [{vid_idx}/{len(videos)}] âœ“" if success else f"    [{vid_idx}/{len(videos)}] âœ—")
            else:
                print(f"  è§†é¢‘: 0 ä¸ª")

            # åˆ¤æ–­æ˜¯å¦æˆåŠŸ
            if len(images) > 0 or len(videos) > 0:
                self.stats["successful"] += 1
            else:
                self.stats["failed"] += 1

            self.stats["notes"].append(note_stats)

            # å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            if idx < len(notes):
                time.sleep(self.delay)

        # ä¿å­˜ä¸‹è½½æŠ¥å‘Š
        print(f"\n[3/3] ç”ŸæˆæŠ¥å‘Š...")
        self.stats["end_time"] = datetime.now().isoformat()

        report_path = author_dir / "download_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.stats, f, ensure_ascii=False, indent=2)

        # æ‰“å°æ€»ç»“
        print("\n" + "="*60)
        print("ä¸‹è½½å®Œæˆï¼")
        print("="*60)
        print(f"ä¿å­˜ä½ç½®: {author_dir}")
        print(f"ç¬”è®°æ€»æ•°: {self.stats['total_notes']}")
        print(f"æˆåŠŸä¸‹è½½: {self.stats['successful']}")
        print(f"æ— å†…å®¹/å¤±è´¥: {self.stats['failed']}")
        print(f"å°é¢å›¾ç‰‡: {self.stats['total_covers']}")
        print(f"é«˜æ¸…å›¾ç‰‡: {self.stats['total_images']}")
        print(f"è§†é¢‘æ–‡ä»¶: {self.stats['total_videos']}")
        print(f"\næŠ¥å‘Šæ–‡ä»¶: {report_path.name}")
        print("="*60)

        return self.stats


def load_config(config_file: str = "config.json") -> Dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = Path(config_file)

    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        # åˆ›å»ºé»˜è®¤é…ç½®
        default_config = {
            "cookie": "",
            "output_dir": "downloads",
            "delay": 0.5,
            "max_notes": None
        }
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(default_config, f, ensure_ascii=False, indent=2)
        print(f"âœ“ å·²åˆ›å»ºé…ç½®æ–‡ä»¶: {config_file}")
        print(f"  è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„ Cookie")
        return default_config


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å°çº¢ä¹¦åšä¸»ç¬”è®°è‡ªåŠ¨ä¸‹è½½å™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹ï¼š

1. ä¸‹è½½æŒ‡å®šåšä¸»çš„æ‰€æœ‰ç¬”è®°ï¼š
   python xiaohongshu_downloader.py https://www.xiaohongshu.com/user/profile/xxx

2. ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼š
   python xiaohongshu_downloader.py --config

3. æŒ‡å®š Cookieï¼š
   python xiaohongshu_downloader.py <URL> --cookie "your_cookie_here"

4. é™åˆ¶ä¸‹è½½æ•°é‡ï¼š
   python xiaohongshu_downloader.py <URL> --max-notes 10

5. æŒ‡å®šè¾“å‡ºç›®å½•ï¼š
   python xiaohongshu_downloader.py <URL> --output ./my_downloads

è·å– Cookie æ–¹æ³•ï¼š
1. æ‰“å¼€æµè§ˆå™¨è®¿é—® https://www.xiaohongshu.com
2. ç™»å½•è´¦å·
3. æŒ‰ F12 æ‰“å¼€å¼€å‘è€…å·¥å…·
4. åˆ‡æ¢åˆ° Network æ ‡ç­¾
5. åˆ·æ–°é¡µé¢ï¼Œç‚¹å‡»ä»»æ„è¯·æ±‚
6. åœ¨å³ä¾§ Request Headers ä¸­æ‰¾åˆ° Cookie
7. å¤åˆ¶æ•´ä¸ª Cookie å­—ç¬¦ä¸²
        """
    )

    parser.add_argument('url', nargs='?', help='åšä¸»ä¸»é¡µURL')
    parser.add_argument('--cookie', '-c', help='å°çº¢ä¹¦ Cookie')
    parser.add_argument('--output', '-o', default='downloads', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šdownloadsï¼‰')
    parser.add_argument('--max-notes', '-n', type=int, help='æœ€å¤§ä¸‹è½½ç¬”è®°æ•°')
    parser.add_argument('--delay', '-d', type=float, default=0.5, help='è¯·æ±‚å»¶è¿Ÿï¼ˆç§’ï¼Œé»˜è®¤ï¼š0.5ï¼‰')
    parser.add_argument('--config', action='store_true', help='ä½¿ç”¨é…ç½®æ–‡ä»¶')

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    if args.config:
        config = load_config()
        cookie = config.get('cookie') or args.cookie
        output_dir = config.get('output_dir', args.output)
        delay = config.get('delay', args.delay)
        max_notes = config.get('max_notes')

        # ä»é…ç½®æˆ–å‘½ä»¤è¡Œè·å– URL
        url = config.get('url') or args.url
        if not url:
            print("âŒ é”™è¯¯ï¼šè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® url æˆ–é€šè¿‡å‘½ä»¤è¡Œå‚æ•°ä¼ å…¥")
            print("   é…ç½®æ–‡ä»¶ï¼šconfig.json")
            print("   ç¤ºä¾‹ï¼špython xiaohongshu_downloader.py <URL> --config")
            return
    else:
        cookie = args.cookie
        output_dir = args.output
        delay = args.delay
        max_notes = args.max_notes
        url = args.url

    # æ£€æŸ¥ URL
    if not url:
        parser.print_help()
        print("\nâŒ é”™è¯¯ï¼šè¯·æä¾›åšä¸»ä¸»é¡µURL")
        print("   ç¤ºä¾‹ï¼špython xiaohongshu_downloader.py https://www.xiaohongshu.com/user/profile/xxx")
        return

    # æ£€æŸ¥ Cookie
    if not cookie:
        print("âš ï¸  è­¦å‘Šï¼šæœªæä¾› Cookie")
        print("   æ—  Cookie æ—¶åªèƒ½è·å–ç¬”è®°å¡ç‰‡ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€å°é¢ã€ç‚¹èµæ•°ï¼‰")
        print("   æœ‰ Cookie æ—¶å¯ä»¥è·å–å®Œæ•´çš„é«˜æ¸…å›¾ç‰‡å’Œè§†é¢‘ä¸‹è½½é“¾æ¥")
        print("\nğŸ’¡ æç¤ºï¼šä½¿ç”¨ --cookie å‚æ•°æˆ–ç¼–è¾‘ config.json æ–‡ä»¶æä¾› Cookie")
        print("")
        response = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ")
        if response.lower() != 'y':
            print("å·²å–æ¶ˆ")
            return

    # åˆ›å»ºä¸‹è½½å™¨å¹¶æ‰§è¡Œä¸‹è½½
    downloader = XiaohongshuDownloader(
        cookie=cookie,
        output_dir=output_dir,
        delay=delay
    )

    try:
        downloader.download_author_notes(url, max_notes=max_notes)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
    except Exception as e:
        print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
